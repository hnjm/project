Neural Networks:

- Idee
- Grundsätzliche Funktionsweise
- Layer
- Gewichte
- Backpropagation

CNNs als Spezialfall:

- Besonderheiten
- spezielle Layer
	- Convs
	- Pooling
	- Upsampling
	- Fully Connected
	- ...
- Vor- und Nachteile

Link-Sammlung:

CNNs:
https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/
http://cs231n.github.io/convolutional-networks/
https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/
http://deeplearning.net/tutorial/lenet.html
https://deeplearning4j.org/convolutionalnetwork.html

NNs:
http://neuralnetworksanddeeplearning.com/chap1.html
http://neuralnetworksanddeeplearning.com/
http://www.deeplearningbook.org/


1 NEURONALE NETZE:

Im Rahmen des maschinellen Lernens stellen die sogenannten neuronalen Netze einen elementaren Ansatz dar,
der in vielen weiteren Modellen Verwendung findet. Neuronale Netze und auch das maschinelle Lernen an sich
stellen eine andere Herangehensweise dar, als die, die man von "gewöhnlichen" Algorithmen gewohnt ist.

Anstatt dem System eine eindeutige Abfolge von Anweisungen mitzuteilen, um eine konkrete Problemstellung
zu lösen, definiert man ein Modell und konfrontiert dieses mit verschiedenen Beispielen - die Beispiele
sind dabei Tupel aus Eingangsgröße und erwarteter Ausgangsgröße. Die Eingabe sind dabei häufig Bilder und die
Ausgaben konkrete Klassen, um beispielsweise Hunde von Katzen unterscheiden zu können.

Anstatt nun algorithmisch zu definieren, was einen Hund von einer Katze unterscheidet, überlässt man es dem zuvor
erstellten Modell anhand der gegebenen Eingaben und erwarteten Ausgaben, eigenständig Regeln abzuleiten, um mit
dessen Hilfe auch unbekannte Eingaben klassifizieren zu können.

Dieser Ansatz kann auch als "Soft Computing" bezeichnet werden.

1.1 PERZEPTRON

Als elementaren Bestandteil eines neuronalen Netzes kann das sogenannte "Perzeptron" angesehen werden - dieses stellt
die kleinste Einheit eines neuronalen Netztes dar und kann auch als "künstliches Neuron" bezeichnet werden.

Grundsätzlich akzeptiert ein Neuron einen beliebig großen Input bestehend aus den Features x1, x2, ... xn und
berechnet daraus ein Ergebnis.

docu_img_01

Im gezeigten Bild ist beispielsweise ein Neuron dargestellt, das drei Inputgrößen akzeptiert und daraus einen Output
produziert. Um den Output zu berechnen werden sogenannte "Gewichte" (weights) eingeführt. Ob das Neuron 0 oder 1 als
Output liefert, hängt dann davon ab, ob die gewichtete Summe der Eingangsgrößen einen zu definierenden Schwellwert
überschreitet.

Dies kann anhand des nachfolgenden Bilds verdeutlicht werden:

docu_img_02

Dies ist das grundlegende Modell. Grundsätzlich kann man sich das Perzeptron als einen "Entscheidungs-Unterstützer"
vorstellen, der eine Entscheidung trifft, in dem er konkrete Fakten mit einem bestimmten Gewicht versieht.

Das gezeigte Modell ist augenscheinlich sehr simpel und noch sehr weit von dem entfernt, was man als ein neuronales
Netz bezeichnen würde. Es ist allerdings ohne Weiteres denkbar, das gezeigte Model komplexer zu gestalten, indem
mehrere Perzeptrons miteinander verknüpft werden, so dass beispielsweise das nachfolgende Netzwerk entstehen könnte:

docu_img_03

In Grafik <docu_img_02> wurde ein Schwellwert eingeführt, der überschritten werden muss, damit ein Perzeptron
"aktiviert" wird. Um das Modell zu vereinheitlichen, kann der sogenannte "Bias" definiert werden, der den
negativen Schwellwert darstellt. Durch diese Maßnahme kann die Aktivierungsfunktion des Perzeptrons dann geschrieben
werden als:

docu_img_04

Inhaltlich kann das Bias als ein Maß verstanden werden, aus dem hervorgeht, wie "leicht" ein Perzeptron aktiviert
werden kann. Nimmt der Bias einen großen Wert an, so kann das Perzeptron einen Wert von 1 annehmen, auch wenn das
Produkt aus den Gewichten und den Eingangsgrößen einen negativen Wert annimmt. Gleiches gilt selbstverständlich auch für
einen kleinen Bias, der zur Folge hat, dass ein Perzeptron nicht so "leicht" aktiviert werden kann.

1.2 Sigmoid-Neuronen

Eine Weiterentwicklung des zuvor vorgestellten Modells stellen Sigmoid-Neuronen dar. Diese Weiterentwicklung wird
dann erforderlich, wenn das Anpassen der Gewichte - also letztlich das "Lernen" - betrachtet wird. Dabei ist das Ziel,
dass eine "kleine" Anpassung eines Gewichts auch nur eine "kleine" Änderung des Outputs zur Folge hat. Das zuvor
betrachtete Perzeptron ist lediglich in der Lage 0 oder 1 als Output zu liefern, so dass Änderungen an den Gewichten
keine stetige Änderung des Outputs zur Folge haben, sondern "folgenlos" bleiben können bis irgendwann ein Sprung von 0
auf 1 oder umgekehrt stattfindet, was wiederum eine große Änderung darstellt.
Die Weiterentwicklung besteht nun in einer Verfeinerung der Aktivierungsfunktion. Anstatt eine "Sprungfunktion" zu
verwenden, die lediglich 0 und 1 als Funktionswert annehmen kann, wird die sogenannte "Sigmoid Funktion" eingeführt,
die die folgende Form hat:

docu_img_05

Der entscheidende Unterschied kann an den beiden nachfolgenden Grafiken verdeutlicht werden, die jeweils die Kurve
der entsprechenden Funktion darstellen:

docu_img_06

docu_img_07

1.3 Architektur neuronaler Netze

Mit diesen Bestandteilen als Ausgangspunkt können nun tatsächlich konkretere Neuronale Netze und deren Architekturen
eingeführt werden. Neuronale Netze bestehen üblicherweise aus mehreren Schichten, den sogenannten "Layern". Diese lassen
sich grundsätzlich in drei Kategorien aufteilen: Input, Hidden und Output. Neuronale Netze beinhalten für gewöhnlich
ein Input-Layer und ein Output-Layer sowie dazwischen beliebig viele Hidden-Layer. Die Form der Input- und Output-Layer
ist dabei sehr naheliegend: das Input-Layer hat die gleiche Struktur wie die des Inputs und das Output-Layer hat
entsprechend die gleiche Struktur wie der Output.
Angenommen es sollen Bilder der Größe 28x28 Pixel klassifiziert werden und es gibt 10 mögliche Klassen, dann besteht das
Input-Layer aus 28x28 = 784 Neuronen und das Output-Layer aus 10 Neuronen.
Lediglich der Bereich zwischen Input- und Output-Layer - die Hidden-Layer - lässt sich nicht ohne Weiteres aus dem Input
oder dem Output ableiten. Es gibt lediglich Heuristiken, die beim Design der Hidden-Layer angewandt werden können,
allerdings keine konkreten Regeln, die befolgt werden müssen. Diese Struktur kann anhand des nachfolgenden Bilds
verdeutlicht werden, bei dem - um die Übersichtlichkeit zu wahren - das Input-Layer etwas komprimiert dargestellt wird:

docu_img_08

1.4 Lernen - Das Anpassen der Gewichte

Das "Lernen" stellt den zentralen Ansatz von neuronalen Netzes dar. Eng im Zusammenhang mit dem Lernen steht eine
Kosten-Funktion, die häufig auch als Verlust-Funktion bezeichnet werden kann. Diese stellt letztlich den Fehler zwischen
dem Erwartungswert und dem tatsächlichen Wert, den das neuronale Netz berechnet, dar. Mathematisch betrachtet ist das
grundlegende Prinzip des Lernens diese Funktion zu minimieren, also zu gewährleisten, dass die Abweichungen zwischen
Erwartungswert und tatsächlichem Wert möglichst gering sind. Es sind grundsätzlich viele verschiedene Verlust-Funktionen
denkbar, eine, die jedoch eine breite Verwendeung findet, ist die quadratische Kosten-Funktion - auch als "mean squared
error" (MSE) bezeichnet.

docu_img_09

Dabei beschreiben w und b die Gewichte bzw. die Bias des neuronalen Netzes und n stellt die Anzahl der Trainingsdaten
dar. Der Vektor a beschreibt den Output des Netzes und y(x) stellt den Erwartungswert zu einem Input x dar.
Das Ziel besteht nun darin, die Gewichte und Bias so zu manipulieren, dass die gezeigte Funktion einen möglichst kleinen
Wert annimmt.

<<< GRADIENT_DESCENT in ein paar ruhigen Minuten schreiben :-) >>>

1.5 Convolutional Networks

Insbesondere bei der Klassifizierung von Bildern hat sich eine bestimmte Art von neuronalen Netzen als besonders passend
herausgestellt - dabei handelt es sich um die sogenannten "Convolutional Networks". Diese zeichnen sich dadurch aus,
dass sie auch die räumliche Struktur der Bilder berücksichtigen: Während herkömmliche "fully connected" neuronale Netze
sämtliche Pixel gleich behandeln würden, unabhängig davon, ob sie beispielsweise benachbart sind oder nicht, betrachten
Convolutional Networks immer nacheinander konkrete Abschnitte eines Bilds, um Strukturen zwischen benachbarten Pixeln
erkennen und somit verarbeiten zu können.
Dabei liegen den Convolutional Networks im Wesentlichen drei Ideen zugrunde:

1) Local receptive field
2) Shared weights
3) Pooling

1.5.1 Wesentliche Konzepte von Convolutional Networks

Diese Bestandteile sollen nun nachfolgend einzeln genauer betrachtet werden.

1.5.1.1 Local receptive field

Für das Verständnis des lokalen rezeptiven Felds ("local receptive field") empfiehlt es sich, die Input-Neuronen des
Convolutional Networks nicht als vertikale Linie von Neuronen, sondern vielmehr in den Dimensionen des Bildes, das von
dem Netzwerk betrachtet werden soll, zu visualisieren. Werden beispielsweise Bilder der Größe 28x28 Pixel betrachtet
entspräche das dem nachfolgenden Input-Layer:

docu_img_10

Im Unterschied zu "herkömmlichen" neuronalen Netzen, bei denen üblicherweise alle Input-Neuronen mit allen Neuronen des
nachfolgenden Hidden-Layers verbunden werden, besteht die Besonderheit nun darin, dass jedes Neuron des Hidden-Layers
mit einem kleinen Bereich des Inputs verbunden wird. Dieses Vorgehen kann anhand des folgenden Bildes veranschaulicht
werden:

docu_img_11

Dieses lokale rezeptive Feld wird dann gemäß der Konfiguration über das Input-Bild "bewegt", so dass alle Input-Neuronen
besucht werden. Demnach sähe der zweite Schritt - unter der Annahme, dass das Feld immer um ein Pixel verschoben wird -
folgendermaßen aus:

docu_img_12

Auf diese Art und Weise entsteht das erste Hidden-Layer dessen Größe selbstverständlich etwas kleiner ist, als die Größe
des Input-Layers. Geht man von einem Input-Bild der Größe 28x28 Pixel und einem lokalen rezeptiven Feld der Größe 5x5
Pixel aus, so folgt daraus ein erstes Hidden-Layer der Größe 24x24 Pixel.

1.5.1.2 Shared weights

Jedes Neuron des Hidden-Layers verfügt wie üblich über einen Bias und - im Falle eines lokalen rezeptiven Felds der
Größe 5x5 Pixel - über 5x5 Gewichte. Die Besonderheit besteht nun darin, dass diese Gewichte und Bias für ALLE Neuronen
des Hidden-Layers gleich gelten. Inhaltlich hat dies zur Folge, dass ein konkretes Hidden-Layer genau eine konkrete
"Auffälligkeit" extrahiert. Solch eine konkrete "Auffälligkeit" könnte beispielsweise eine vertikale oder horizontale
Linie sein, die durch die Verwendung des lokalen rezeptiven Felds, das sich über das Bild bewegt, an beliebigen
Positionen aufgespürt werden kann. Üblicherweise reicht es nicht aus, nur eine "Auffälligkeit" aufzuspüren. Aus diesem
Grund besteht ein einziges Layer häufig aus mehreren parallelen feature maps (TODO: Begriff einführen).

So könnte ein einziges Hidden-Layer beispielsweise die nachfolgende Form haben, durch das dann drei verschiedene
Auffälligkeiten extrahiert werden würden:

docu_img_13

Ein weiterer wesentlicher Vorteil bei der Verwendung von "shared weights" besteht darin, dass die Anzahl der zu
trainierenden Variablen um ein Vielfaches verringert wird, wodurch ein schnelleres Lernen ermöglicht werden kann.
Eine einzige feature map (TODO) würde bei den bisher betrachteten Dimensionen durch 5x5 = 25 Gewichte und einen Bias,
also insgesamt 26 Parameter definiert werden. Selbst wenn ein Hidden-Layer aus 20 features maps bestünde, so würde dies
im Ergebnis zu "nur" 20x26 = 520 Parametern führen.
Wird ein fully connected Layer bestehend aus 30 Neuronen und das gleiche Input-Layer wie zuvor betrachtet, so folgt
daraus, dass insgesamt (28 x 28) x 30 + 30 = 23550 Parameter in jedem Schritt des Lernens angepasst werden müssen.

1.5.1.3 Pooling

Die zuvor vorgestellten Layer, die durch die Verwendung des lokalen rezeptiven Felds und gemeinsam geteilter Gewichte
enstehen, werden gemeinhin als "convolutional" Layer bezeichnet. Von diesen kann ein weiterer wesentlicher Bestandteil
von convolutional networks abgegrenzt werden - die sogenannten "pooling" Layer. Diese Art von Layer folgt für
gewöhnlich auf die zuvor vorgestellten "convolutional" Layer und hat zur Aufgabe, die dadurch gewonnenen Informationen
zu vereinfachen.
Das grundsätzliche Vorgehen kann durchaus mit dem des convolutional Layers verglichen werden - auch bei den pooling
Layers kommt ein Feld zum Einsatz, dass sich über das Ergebnis des vorherigen Schrittes bewegt. Es könnte sich
beispielsweise um ein Feld der Größe 2x2 handeln. Dieses würde somit immer 4 Neuronen betrachten und - im Falle des
sogenannten max-poolings (einer konkreten Ausprägung des Poolings) - das größte von ihnen auswählen.

Bildlich kann dies auf die folgende Art und Weise veranschaulicht werden:

docu_img_14

Dadurch, dass vier Neuronen auf ein Neuron projeziert werden, verringert sich die Größe bei diesem konkreten Beispiel
von 24x24 auf 12x12. Dieses Vorgehen wird selbstverständlich auf alle feature maps des vorherigen convolutional Layers
angewendet, so dass das folgende Ergebnis entsteht.

docu_img_15

1.5.2 Beispielhaftes Convolutional Network

Nachdem die wesentlichen Bestandteilen eines convolutional Netzes vorgestellt worden sind, können diese nun miteinander
verknüpft werden, um die Architektur eines exemplarischen Netzes zu veranschaulichen. Wie auch bei "normalen" neuronalen
Netzen orientieren sich Input- und Output-Layer an der Struktur des Inputs bzw. Outputs. Dazwischen befinden sich
abwechselnd convolutional und pooling Layer, die grundsätzlich beliebig oft hintereinander geschaltet werden können.
Demnach sähe ein sehr simples convolutional Netzwerk beispielsweise folgendermaßen aus:

docu_img_16










