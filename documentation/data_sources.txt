Datenquellen und Aufbereitung

Als grundlegende Datenquelle wurde die "color FERET Database", die von dem National Institute of Standards and Technology veröffentlicht wurde, verwendet. [8] Die Datenbank umfasst 11.338 Gesichtsbilder von 1.208 Menschen und hält neben Metadaten über Pose, Geschlecht, Ethnie und Alter auch weiterführende Daten bereit wie Augenposition und Kamerawinkel. Die Daten liegen im Portable Pixmap Format RGB- und im Graustufenformat in einer vor Auflösung von 512x768 Pixeln vor.

Um trotz der vergleichsweise geringen Datenmenge 1) gute Ergebnisse erzielen zu können, beschränkt sich diese Arbeit auf die Verwendung möglichst homogener Bilder unterschiedlicher Personen. Von besonderem Interesse ist hierbei die Pose des Abgebildeten. Die Datenbank unterscheidet Frontal- und Profilbilder sowie Bilder, in denen der Kopf um einen bestimmten Winkel gedreht ist. Als grundlegenden Datensatz wurde sich für die Frontalbilder entschieden, da diese mit 2.722 Bilder von 994 Personen den größten Teildatensatz ausmachen.

Die benötigten Testdatensätze wurde mithilfe von ImageMagick [11] in Version x.y. aufbereitet. Um die Komplexität der Problemstellung weiter zu reduzieren, wurden die Bilder grauskaliert und auf 12,5% der Ursprungsgröße skaliert, sodass die Trainigsdaten noch eine Auflösung von 64x96 Pixeln haben. Es wurden vier unterschiedliche Testdatensätze mit folgenden Commandline-Befehlen generiert 2):

convert - Synopsis [12]
convert [input-options] input-file [output-options] output-file

$> convert <input_file.ppm> -set colorspace Gray -separate -average -scale 12.5% -gaussian-blur 0x3 <output_file.ppm>
[Image_Thumb] [Image_blur_03]
Weichzeichnen, Sigma 3

$> convert <input_file.ppm> -set colorspace Gray -separate -average -scale 12.5% -gaussian-blur 0x6 <output_file.ppm>
[Image_Thumb] [Image_blur_06]
Weichzeichnen, Simga 6

$> convert <input_file.ppm> -set colorspace Gray -separate -average -scale $(( bc <<< "scale=100;100/5" ))% -scale 500% <output_file.ppm>
[Image_Thumb] [Image_mosaic_05]
Mosaic, Kantenlänge 5

$> convert <input_file.ppm> -set colorspace Gray -separate -average -scale $(( bc <<< "scale=100;100/10" ))% -scale 1000% <output_file.ppm>
[Image_Thumb] [Image_mosaic_10]
Mosaic, Kantenlänge 10

### TODO: Lerndauer, hier? Vllt im Kapitel zum Aufbau des von uns verwendeten Netzwerkes ###

1) Vergleichbare Projekte [9, 10] verwenden hingegen 60.000 bis 300.000 Bilder.
2) Das anhängende BASH-Skript scripts/create_images.sh erzeugt die Testdaten. Notwendig hierfür sind die Pakete "imagemagick" und "imagemagick-doc". [11]

[8] NIST, color FERET Database. (https://www.nist.gov/itl/iad/image-group/color-feret-database)
[9] Richard McPherson, Rezar Shokri, Vitali Shmatikov, Defeating Image Obfuscation with Deep Learning. (https://arxiv.org/pdf/1609.00408.pdf)
[10] "Jenkspt", Enhancher. (https://github.com/jenkspt/enhancer)
[11] ImageMagick Studio LLC, ImageMagick. (https://www.imagemagick.org/)
[12] Linux man page, Convert. (https://linux.die.net/man/1/convert)